{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f6f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import sunau\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import librosa\n",
    "import python_speech_features\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import pywt # Python wavelet transform implementation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # Interfaces and base classes for pipeline components\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.fft import fft, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436b64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Normalizes sample data to the interval (-1, 1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, nbits: int, signed: bool):\n",
    "        self.signed = signed\n",
    "        self.nbits = nbits\n",
    "        if self.signed:\n",
    "            self.nbits = self.nbits-1\n",
    "    \n",
    "    def transform(self, samples: np.array) -> np.array:\n",
    "        normalized_samples = samples/(2**self.nbits) \n",
    "        normalized_samples = np.clip(normalized_samples, -1, 1)\n",
    "        return normalized_samples\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4b4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormFFT(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n: int = 5000):\n",
    "        self.n=n\n",
    "        \n",
    "    def transform(self, normalized_samples: np.array) -> (np.array, np.array, np.array):\n",
    "        transformed_samples = fft(normalized_samples, n=self.n) # calculate fourier transform (complex numbers list)\n",
    "        #length = len(transformed_samples)/2  # you only need half of the fft list (real signal symmetry)\n",
    "        #halved_transform = transformed_samples[:, 0:int(length-1)]\n",
    "        #return np.abs(halved_transform), np.real(halved_transform), np.imag(halved_transform)\n",
    "        return np.abs(transformed_samples)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99e8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Compute approximation coefficients of a selected wavelet.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wavelet_name : str, default='db1'\n",
    "        Wavelet to use in transformation.\n",
    "        Must be a wavelet name defiend in PyWavelets library\n",
    "        See http://wavelets.pybytes.com/\n",
    "    mode : str, default='symmetric'\n",
    "        Extrapolation mode for transform.\n",
    "        See https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "        The number of features of the data passed to :meth:`fit`.\n",
    "    wavelet_name : str, default='db1'\n",
    "        Wavelet to use in transformation.\n",
    "        See http://wavelets.pybytes.com/\n",
    "    mode : str, default='symmetric'\n",
    "        Extrapolation mode for transform.\n",
    "        See https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 wavelet_name: str = 'db1',\n",
    "                 mode: str = 'symmetric'):\n",
    "        self.wavelet_name = wavelet_name\n",
    "        self.mode = mode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"A reference implementation of a fitting function for a transformer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : None\n",
    "            There is no need of a target in a transformer, yet the pipeline API\n",
    "            requires this parameter.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Each row of X must have the same length\n",
    "        # In other words, signals need to be truncated or padded to a fixed length\n",
    "        # prior to passing to this transformer.\n",
    "        self.n_features_ = X.shape[1]\n",
    "\n",
    "        # Other checks go here\n",
    "        \n",
    "        # Return the transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Compute wavelet transform on input data X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse-matrix}, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array, shape (n_samples, n_features)\n",
    "            The array containing the wavelet transform approximation coefficients from each row of X\n",
    "            in ``X``.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, 'n_features_')\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Check that the input is of the same shape as the one passed\n",
    "        # during fit.\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError('Shape of input is different from what was seen'\n",
    "                             'in `fit`')\n",
    "            \n",
    "        (cA, cD) = pywt.dwt(X, self.wavelet_name, self.mode)\n",
    "        return cA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc9494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudio(audioPath):\n",
    "    sample_rate, samples = wavfile.read(audioPath)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    spectrogram = np.log(spectrogram)\n",
    "    transposed_spec = spectrogram.transpose()\n",
    "    freq_list = list(frequencies)\n",
    "    #freq_list = [str(f) for f in freq_list]\n",
    "    #freq_list = [f + \" Hz\" for f in freq_list]\n",
    "    audio_df = pd.DataFrame(transposed_spec, index = times, columns = freq_list )\n",
    "    audio_df.index = times\n",
    "    audio_df\n",
    "    return [audio_df, samples, sample_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184f20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import numpy as np\n",
    "def make_random_signal(freq1, freq2, length=1000, noise_level=25):\n",
    "    \"\"\"\n",
    "    Make a wave and add random noise\n",
    "    The signal is composed of x/100 and x/20. The amplitude and horizontal shift is randomly chosen\n",
    "    \"\"\"\n",
    "    shift = randrange(101) # Random int between 0 and 100\n",
    "    amplitude_f1 = randrange(0,1001) # Amplitude of frequency 1\n",
    "    amplitude_f2 = randrange(0,1001) # Amplitude of frequency 2\n",
    "    raw_signal = np.array([amplitude_f1*np.sin((x+shift)*freq1) + amplitude_f2*np.cos((x+shift)*freq2) for x in range(0,length)])\n",
    "    noisy_signal = raw_signal + np.random.normal(0, noise_level, length)\n",
    "    noisy_signal = noisy_signal.astype(np.int16)\n",
    "    return noisy_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5f5ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal1: 36.5, 95.2\n",
      "signal2: 100, 100\n"
     ]
    }
   ],
   "source": [
    "freq1a= randrange(1, 1000)/10\n",
    "freq1b= randrange(1, 1000)/10\n",
    "freq2a= randrange(1, 1000)/10\n",
    "freq2b= randrange(1, 1000)/10\n",
    "\n",
    "signal1 = make_random_signal(freq1a, freq1b, 44100)\n",
    "signal2 = make_random_signal(freq2a, freq2b, 44100)\n",
    "print(\"signal1: \" + str(freq1a) + \", \" + str(freq1b))\n",
    "print(\"signal2: \" + str(100) + \", \" + str(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08796f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_freq1=randrange(1, 1000)/10\n",
    "rand_freq2=randrange(1, 1000)/10\n",
    "class1 = [make_random_signal(20, rand_freq1, 44100)  for i in range(1, 1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f29da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2 = [make_random_signal(50, rand_freq2, 44100)  for i in range(1, 1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad8c843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44100,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e167e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = ([0]*1000) + ([1]*1000)\n",
    "y_train = np.array(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17050eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 44100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = class1 + class2\n",
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e62f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "write(\"signal1.wav\", 44100, signal1)\n",
    "write(\"signal2.wav\", 44100, signal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dfc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipe = Pipeline([('normalizer', Normalizer(16, True)), \n",
    "                 ('normfft', NormFFT(44100)),\n",
    "                 ('minmaxscaler', MinMaxScaler()),\n",
    "                 ('svc', SVC())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6f0cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('normalizer', Normalizer(nbits=15, signed=True)),\n",
       "                ('normfft', NormFFT(n=44100)), ('minmaxscaler', MinMaxScaler()),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a26e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class1 = [make_random_signal(20, rand_freq1, 44100)  for i in range(1, 101)]\n",
    "test_class2 = [make_random_signal(50, rand_freq2, 44100)  for i in range(1, 101)]\n",
    "X_test = test_class1 + test_class2\n",
    "X_test = np.array(X_test)\n",
    "y_test = ([0]*100) + ([1]*100)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f77092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13bd19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 44100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "788d7914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('normalizer', Normalizer(nbits=15, signed=True)),\n",
       "  ('normfft', NormFFT(n=44100)),\n",
       "  ('minmaxscaler', MinMaxScaler()),\n",
       "  ('svc', SVC())],\n",
       " 'verbose': False,\n",
       " 'normalizer': Normalizer(nbits=15, signed=True),\n",
       " 'normfft': NormFFT(n=44100),\n",
       " 'minmaxscaler': MinMaxScaler(),\n",
       " 'svc': SVC(),\n",
       " 'normalizer__nbits': 15,\n",
       " 'normalizer__signed': True,\n",
       " 'normfft__n': 44100,\n",
       " 'minmaxscaler__clip': False,\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'svc__C': 1.0,\n",
       " 'svc__break_ties': False,\n",
       " 'svc__cache_size': 200,\n",
       " 'svc__class_weight': None,\n",
       " 'svc__coef0': 0.0,\n",
       " 'svc__decision_function_shape': 'ovr',\n",
       " 'svc__degree': 3,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'rbf',\n",
       " 'svc__max_iter': -1,\n",
       " 'svc__probability': False,\n",
       " 'svc__random_state': None,\n",
       " 'svc__shrinking': True,\n",
       " 'svc__tol': 0.001,\n",
       " 'svc__verbose': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc0d7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 9, 13, 0, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this cell and next are troubleshooting syntax and refreshers\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "c = np.array([9, 10, 11, 12])\n",
    "d = np.array([13, 14, 15, 16])\n",
    "e = np.array([0]*4)\n",
    "f = np.array([1]*4)\n",
    "g = [a, b, c, d, e, f]\n",
    "test = [g[i][0] for i in range(0, len(g))]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8977ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i think this syntax was messing us up\n",
    "#using g[x][y] returns the y-th element from the x-th array of g (normal/expected behavior)\n",
    "#using g[\"some-slice\"][y] operates on the slice?\n",
    "length = len(g)/2  # you only need half of the fft list (real signal symmetry)\n",
    "g[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ba016d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desk_path_list = ['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap1.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap2.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap3.wav',\n",
    "                     'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\desk_tap4.wav']\n",
    "key_path_list = ['C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press1.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press2.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press3.wav',\n",
    "                 'C:\\\\Users\\\\kbk17\\\\EspionageDomainExploration\\\\key_press4.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9665f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "desk_read_output = [loadAudio(x) for x in desk_path_list]\n",
    "key_read_output = [loadAudio(x) for x in key_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff4a0fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  -17,  -102,   -80, ..., -2649, -2548, -2529], dtype=int16),\n",
       " array([  359,   348,   358, ..., -1108, -1044, -1052], dtype=int16),\n",
       " array([  698,   713,   750, ..., -2063, -2160, -2139], dtype=int16),\n",
       " array([  113,   179,    99, ..., -1689, -1665, -1721], dtype=int16)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desk_samples = [desk_read_output[i][1] for i in range(0,len(desk_read_output))]\n",
    "desk_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94847f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1684, -1785, -1415, ...,  1145,  1071,   310], dtype=int16),\n",
       " array([-5741, -5481, -5774, ..., -3737, -3746, -3949], dtype=int16),\n",
       " array([   163,    510,    226, ..., -10299, -10038,  -9722], dtype=int16),\n",
       " array([ -772,  -757, -1090, ...,    65,   338,   150], dtype=int16)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_samples = [key_read_output[i][1] for i in range(0,len(key_read_output))]\n",
    "key_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aeff64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13435"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = key_samples + desk_samples\n",
    "max_length = 0\n",
    "for s in samples:\n",
    "    if len(s) > max_length:\n",
    "        max_length = len(s)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ddd7e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [2, 3, 4, 5], [6, 7, 8, 9, 10]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing; remember np.pad() doesn't mutate input array but rather returns a new array\n",
    "padded_b = []\n",
    "b = [[0,1], [2,3,4,5], [6,7,8,9,10]]\n",
    "for s in b:\n",
    "    np.pad(s, (0, 5-len(s)), 'constant', constant_values=-2**15)\n",
    "    padded_b.append(s)\n",
    "padded_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8491b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1684, -1785, -1415, ...,  1145,  1071,   310], dtype=int16),\n",
       " array([ -5741,  -5481,  -5774, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([   163,    510,    226, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([  -772,   -757,  -1090, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([   -17,   -102,    -80, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([   359,    348,    358, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([   698,    713,    750, ..., -32768, -32768, -32768], dtype=int16),\n",
       " array([   113,    179,     99, ..., -32768, -32768, -32768], dtype=int16)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_samples = []\n",
    "for s in samples:\n",
    "    padded_s = np.pad(s, (0, max_length-len(s)), 'constant', constant_values=-2**15)\n",
    "    padded_samples.append(padded_s)\n",
    "padded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dda3932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13022"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(padded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03412343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1684, -1785, -1415, ...,  1145,  1071,   310], dtype=int16),\n",
       " array([-5741, -5481, -5774, ..., -3737, -3746, -3949], dtype=int16),\n",
       " array([   163,    510,    226, ..., -10299, -10038,  -9722], dtype=int16),\n",
       " array([ -772,  -757, -1090, ...,    65,   338,   150], dtype=int16),\n",
       " array([  -17,  -102,   -80, ..., -2649, -2548, -2529], dtype=int16),\n",
       " array([  359,   348,   358, ..., -1108, -1044, -1052], dtype=int16),\n",
       " array([  698,   713,   750, ..., -2063, -2160, -2139], dtype=int16),\n",
       " array([  113,   179,    99, ..., -1689, -1665, -1721], dtype=int16)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6512f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1684, -1785, -1415, ...,  1145,  1071,   310], dtype=int16),\n",
       " array([-5741, -5481, -5774, ..., -3737, -3746, -3949], dtype=int16),\n",
       " array([   163,    510,    226, ..., -10299, -10038,  -9722], dtype=int16),\n",
       " array([ -772,  -757, -1090, ...,    65,   338,   150], dtype=int16),\n",
       " array([  -17,  -102,   -80, ..., -2649, -2548, -2529], dtype=int16),\n",
       " array([  359,   348,   358, ..., -1108, -1044, -1052], dtype=int16),\n",
       " array([  698,   713,   750, ..., -2063, -2160, -2139], dtype=int16),\n",
       " array([  113,   179,    99, ..., -1689, -1665, -1721], dtype=int16)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac42118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added dtype=object to avoid jagged nparray error; this is accounted for in NormFFT.transform() (in fft( ..., n=self.n) to be exact)\n",
    "\n",
    "X_train = np.array(samples, dtype=object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2804ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let 0 represent key press, 1 desk tap\n",
    "y_train = [0, 0, 0, 0, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b11323",
   "metadata": {},
   "source": [
    "# Testing model with increased noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 40\n",
    "class1 = [make_random_signal(20, rand_freq1, 44100, noise_level)  for i in range(1, 101)]\n",
    "class2 = [make_random_signal(50, rand_freq2, 44100, noise_level)  for i in range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352966ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = class2[1]\n",
    "x = list(range(0,44100))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9385f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = class1[1]\n",
    "x = list(range(0,44100))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32036c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_classification_model(noise_level):\n",
    "    class1 = [make_random_signal(20, rand_freq1, 44100, noise_level)  for i in range(1, 101)]\n",
    "    class2 = [make_random_signal(50, rand_freq2, 44100, noise_level)  for i in range(1, 101)]\n",
    "    X_test = np.array(class1 + class2)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    a = [0]*100\n",
    "    b = [1]*100\n",
    "    target = a + b\n",
    "    print(\"Prediction at noise level: \" + str(noise_level))\n",
    "    print(y_pred)\n",
    "    cm = confusion_matrix(target, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(target, y_pred)\n",
    "    precision = precision[1]\n",
    "    recall = recall[1]\n",
    "    f1 = f1[1]\n",
    "    support = support[1]\n",
    "    print((precision, recall, f1, support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98736ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_classification_model(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4234eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_classification_model(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand_freq1)\n",
    "print(rand_freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_classification_model(37.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_classification_model(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40807148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = [make_random_signal(20, rand_freq1, 44100, 35)  for i in range(1, 101)]\n",
    "class2 = [make_random_signal(50, rand_freq2, 44100, 35)  for i in range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(class1 + class2)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c377609",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, support = precision_recall_fscore_support(target, y_pred)\n",
    "precision = precision[1]\n",
    "recall = recall[1]\n",
    "f1 = f1[1]\n",
    "support = support[1]\n",
    "(precision, recall, f1, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ced14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e51a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = [make_random_signal(20, rand_freq1, 44100, 40)  for i in range(1, 101)]\n",
    "class2 = [make_random_signal(50, rand_freq2, 44100, 40)  for i in range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0]*100\n",
    "b = [1]*100\n",
    "target = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3980bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(class1 + class2)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f456f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#assessing model at 1.5 the noise\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cm = confusion_matrix(target, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is good practice to perform a confusion matrix (above) and Precision/Recall for all classification models\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1, support = precision_recall_fscore_support(target, y_pred)\n",
    "precision = precision[1]\n",
    "recall = recall[1]\n",
    "f1 = f1[1]\n",
    "support = support[1]\n",
    "(precision, recall, f1, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6b986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9d42b1",
   "metadata": {},
   "source": [
    "# Noise level experiment\n",
    "- Generate training data with higher noise level\n",
    "- Generate test data with same or different noise level\n",
    "- Train model with generated data\n",
    "- Evaluate model performance using sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e2162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
